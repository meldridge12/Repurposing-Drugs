# Drug Repurposing Prediction Using Machine Learning Algorithms

Drug repurposing prediction aims to identify new therapeutic uses for existing drugs. This repository implements a complete machine learning pipeline that integrates DrugBank, CTD and BioSNAP into a unified drug–disease dataset and evaluates several models for prioritizing repurposing candidates.

The **main branch** contains the improved **XGBoost** pipeline, which achieved the strongest Top K performance in our experiments. Implementations of the other models (LightGBM, CatBoost and a deep neural network) are available in the other branches of this repository.

---

## 1. Project Overview

- Integrated data from **DrugBank**, **CTD** (Comparative Toxicogenomics Database) and the **BioSNAP Disease Drug network**.
- Constructed a unified dataset of roughly **1.2 million drug–disease pairs**, with structural, biological and relational features.
- Evaluated multiple models:
  - XGBoost  
  - LightGBM  
  - CatBoost  
  - Deep neural network (PyTorch)  
- Primary evaluation metric:
  - **Top K accuracy**, which measures how often the true disease label appears among the top K predictions for each drug.

On the final integrated dataset, **gradient boosting models, especially XGBoost, performed best**, with strong Top 5 and Top 10 accuracy. The improved XGBoost pipeline in this branch focuses on that model and on detailed evaluation and reporting.

---

## 2. Dataset

### 2.1 Integrated dataset

The project builds a large scale supervised learning dataset by joining three public resources:

- DrugBank: detailed drug information and SMILES structures.  
- CTD: curated chemical gene disease associations.  
- BioSNAP Disease Drug: network of drug disease associations.

After mapping and filtering incompatible identifiers, the integrated dataset contains approximately:

- **1.2 million drug–disease pairs**
- **27 engineered features**
- **245 disease classes**

These features include:

- Chemical descriptors (molecular weight, hydrogen bond counts, logP, fingerprints and related properties).
- Biological associations (drug gene and disease gene links from CTD).
- Disease level embeddings and similarity groupings.
- SMILES derived structural vectors.

### 2.2 Public dataset for this repository

The merged dataset used by the code in this branch is published on Kaggle:

- **Drug Disease Associations**  
  https://www.kaggle.com/datasets/ompatel8/drugdisease-associations

For the improved XGBoost pipeline, a working CSV named:

- `finaldataset.csv`

is used in the code. This CSV should be placed in the root of the repository, alongside the notebooks.

From the integrated dataset, the XGBoost pipeline:

- Loads **300 000** rows as an initial sample.
- Filters diseases to keep only those with **150 to 1000** samples.
- Undersamples each remaining disease to a maximum of **800** samples.

This results in a balanced training dataset of:

- **189 057** samples  
- **576** disease classes  
- **10 original numeric features**  
- **6 engineered features**  
- **16 total features**

---

## 3. Repository Structure (main branch)

Key files in the `main` branch:

- `final_submission.ipynb`  
  Main notebook containing the improved XGBoost drug repurposing pipeline. It defines:
  - Data loading and balancing
  - Preprocessing and feature engineering
  - Model training and evaluation
  - Visualization and reporting
  - Model and report saving

- `testcases_final_submission.ipynb`  
  Notebook that generates a detailed demo report for 10 to 15 randomly selected test cases using the trained XGBoost model.

- `improved_xgboost_model.json`  
  Saved trained XGBoost model produced by the pipeline.

- `improved_model_report.txt`  
  Comprehensive text report summarizing dataset statistics, model configuration, metrics, feature importance and analysis.

- `demo_testcases_report.txt`  
  Text report with detailed Top K predictions and feature values for 15 demo test samples.

- PNG visualizations produced by the pipeline:
  - `disease_distribution.png`
  - `feature_distributions.png`
  - `confusion_matrix.png`
  - `prediction_distribution.png`
  - `metrics_comparison.png`
  - `topk_accuracy.png`
  - `feature_importance.png`
  - `training_history.png`
  - `performance_summary.png`

These files are generated by running the notebooks on `finaldataset.csv`.

---

## 4. Improved XGBoost Pipeline

All code snippets below are implemented in `final_submission.ipynb` (and the equivalent script shown in this description).

### 4.1 Libraries

The pipeline uses standard Python libraries:

- `pandas`, `numpy`
- `matplotlib`, `seaborn`
- `scikit-learn`:
  - `train_test_split`, `StratifiedKFold`
  - `LabelEncoder`, `StandardScaler`
  - classification metrics
- `xgboost` (XGBClassifier)
- `gc`, `warnings`, `datetime`, `collections.Counter`, `time`

### 4.2 Data loading and balancing

The function `load_data_with_balance`:

- Reads `finaldataset.csv` in chunks for memory efficiency.
- Uses the feature columns:

  - `logp_alogps`  
  - `logp_chemaxon`  
  - `logp`  
  - `pka__strongest_acidic_`  
  - `pka__strongest_basic_`  
  - `molecular_weight`  
  - `n_hba`  
  - `n_hbd`  
  - `inferencescore`  
  - `ro5_fulfilled`  
  - `diseasename`

- Filters diseases to keep only those with **150 to 1000** samples.
- Undersamples each disease class to a maximum of **800** samples.
- Downcasts numeric dtypes to reduce memory usage.
- Records dataset statistics in the shared `REPORT_DATA` dictionary.
- Stores timing information in `RUN_TIMERS`.

This step also generates:

- `disease_distribution.png`  
- `feature_distributions.png`

### 4.3 Preprocessing and feature engineering

The function `preprocess_efficiently`:

- Normalizes `ro5_fulfilled` to 0 or 1 from various boolean string forms.
- Imputes missing numeric values with the median for each column.
- Separates features `X` and target `y` (diseasename).
- Records missing values and feature metadata in `REPORT_DATA`.

The function `add_enhanced_features` then creates six engineered features:

1. `logp_mean`  
   Average of `logp_alogps` and `logp_chemaxon`.

2. `h_bond_total`  
   Sum of `n_hba` and `n_hbd`.

3. `pka_range`  
   Difference between `pka__strongest_acidic_` and `pka__strongest_basic_`.

4. `h_bond_ratio`  
   Ratio between donors and acceptors.

5. `mw_per_hbond`  
   Molecular weight per total hydrogen bond count.

6. `logp_variance`  
   Variance of logP across different estimation methods.

After engineering, the dataset has **16 features**. Feature counts and timing are tracked in `REPORT_DATA` and `RUN_TIMERS`.

### 4.4 Label encoding and scaling

- `encode_target` uses `LabelEncoder` to map disease names to integer class labels.
- The top 5 most common diseases and their counts are stored in `REPORT_DATA`.
- `split_and_scale`:
  - Performs an 80 / 20 stratified train test split.
  - Optionally subsamples if the dataset exceeds 200 000 rows.
  - Uses `StandardScaler` to standardize features to float32.
  - Saves train and test sample counts and test size in `REPORT_DATA`.

### 4.5 Improved XGBoost configuration

The function `train_improved_model` builds an `XGBClassifier` with:

- `objective`: `multi:softprob`  
- `num_class`: 576  
- `max_depth`: 4  
- `learning_rate`: 0.05  
- `n_estimators`: 150  
- `subsample`: 0.7  
- `colsample_bytree`: 0.7  
- `min_child_weight`: 10  
- `gamma`: 0.3  
- `reg_alpha`: 0.5  
- `reg_lambda`: 2.0  
- `random_state`: 42  
- `n_jobs`: 4  
- `tree_method`: `hist`  
- `max_bin`: 256  
- `eval_metric`: `mlogloss`  
- `early_stopping_rounds`: 15  

To address class imbalance, it computes class weights:

- `class_weights[class] = total_samples / (num_classes * class_count)`

and passes the resulting `sample_weights` to `model.fit`.

Training logs:

- Best iteration
- Timing for training (`RUN_TIMERS['model_training']`)

### 4.6 Evaluation and visualizations

The function `evaluate_improved_model` computes:

- Train accuracy
- Test Top 1 accuracy
- Test Top 3, Top 5, Top 10 accuracy (using `top_k_accuracy_score`)
- Weighted precision, recall and F1 score
- A classification report for the 10 most frequent diseases

Metrics are stored in `REPORT_DATA`. It also produces:

- `confusion_matrix.png`  
  Confusion matrix over the top 10 most frequent diseases.

- `prediction_distribution.png`  
  Comparison of actual vs predicted class counts for the top 15 diseases.

- `metrics_comparison.png`  
  Bar charts for:
  - Train vs test accuracy
  - Test Top 1 accuracy, precision, recall, F1

- `topk_accuracy.png`  
  Top 1, 3, 5, 10 accuracy plotted as a function of K.

### 4.7 Feature importance and training history

- `show_feature_importance`:
  - Uses `model.feature_importances_`
  - Prints top 15 features with scores
  - Saves `feature_importance.png`

- `plot_history`:
  - Uses `model.evals_result()` to plot:
    - Train vs test log loss
    - Overfitting gap (test loss minus train loss)
  - Saves `training_history.png`
  - Stores initial and final losses in `REPORT_DATA`.

### 4.8 Performance summary dashboard

`create_performance_summary` combines key information from `REPORT_DATA` into a single figure `performance_summary.png`:

- Dataset panel (rows, classes, features, train and test sizes)
- Model performance panel (Top K metrics and F1)
- Model configuration panel (depth, learning rate, number of trees, class weights, best iteration)
- Top 5 most common diseases (bar plot)
- Top 5 most important features (bar plot)

### 4.9 Text reports

#### Comprehensive model report

`generate_improved_report` writes `improved_model_report.txt` containing:

- Dataset statistics and disease distribution summary
- Preprocessing and engineered feature description
- Full list of model hyperparameters
- Training and test performance metrics
- Overfitting analysis and training history
- Ranked feature importance
- Classification report for the top 10 diseases
- Summary of generated output files
- Analysis, insights and recommendations
- Final conclusion on model performance

Key results in this report:

- **Training accuracy:** 0.455684  
- **Testing Top 1 accuracy:** 0.226886  
- **Testing Top 3 accuracy:** 0.777981  
- **Testing Top 5 accuracy:** 0.954565  
- **Testing Top 10 accuracy:** 0.997488  
- **Weighted precision:** 0.229605  
- **Weighted recall:** 0.226886  
- **Weighted F1 score:** 0.207171  

Overfitting gap:

- Train accuracy minus test accuracy: **0.228799** (22.88 percent)

Most important features:

1. `inferencescore` (dominant feature with importance 0.72134072)  
2. `logp_mean`  
3. `logp_variance`  
4. `logp_alogps`  
5. `logp_chemaxon`  
6. `logp`  
7. `mw_per_hbond`  
8. `pka__strongest_basic_`  
9. `pka__strongest_acidic_`  
10. `pka_range`  
11. `molecular_weight`  
12. `h_bond_total`  
13. `n_hbd`  
14. `ro5_fulfilled`  
15. `h_bond_ratio`

The report notes that the improved model reduces overfitting compared to an earlier configuration, achieves strong Top 5 accuracy and focuses on Top K metrics as the most practical evaluation for multi class drug repurposing.

#### Demo test cases report

`generate_demo_testcases_report` builds `demo_testcases_report.txt`:

- Samples **15** random test instances.
- For each test case, prints:
  - Original scale feature values (inverse transformed with the scaler)
  - True disease label
  - Top 5 predicted diseases with probabilities
  - Marking of the correct label if present among the Top 5

Summary for the 15 demo cases:

- **Top 1 accuracy:** 3 / 15 (20.00 percent)  
- **Top 3 coverage:** 9 / 15 (60.00 percent)  
- **Top 5 coverage:** 14 / 15 (93.33 percent)  

These examples are intended for project presentation and qualitative inspection.

---

## 5. Main Pipeline Entry Point

The main orchestration function is:

```python
def main(filepath, sample_size=300000):
    ...


It runs the full sequence:

1. Load balanced data with `load_data_with_balance`.
2. Preprocess with `preprocess_efficiently`.
3. Add engineered features with `add_enhanced_features`.
4. Encode target labels with `encode_target`.
5. Split and scale with `split_and_scale`.
6. Train the improved XGBoost model with `train_improved_model`.
7. Evaluate and plot metrics with `evaluate_improved_model`.
8. Compute feature importance with `show_feature_importance`.
9. Plot training history with `plot_history`.
10. Create performance dashboard with `create_performance_summary`.
11. Print live demo test cases with `show_demo_cases`.
12. Save `improved_xgboost_model.json`.
13. Generate `improved_model_report.txt`.
14. Print pipeline timing summary.

The example usage in the code:

```python
if __name__ == "__main__":
    FILEPATH = 'finaldataset.csv'
    model, scaler, label_encoder, X_test, y_test, feature_names = main(
        FILEPATH,
        sample_size=300000
    )

    generate_demo_testcases_report(
        model=model,
        scaler=scaler,
        le=label_encoder,
        X_test=X_test,
        y_test=y_test,
        feature_names=feature_names,
        n_cases=15,
        top_k=5,
        out_path="demo_testcases_report.txt"
    )
```

When this entry block is executed, the complete improved pipeline runs and both reports are generated.

---

## 6. How to Run

The pipeline expects a standard Python environment with the libraries listed above.

### Step 1. Clone the repository

```bash
git clone https://github.com/meldridge12/Repurposing-Drugs.git
cd Repurposing-Drugs
```

### Step 2. Download the dataset

1. Go to the Kaggle dataset:
   `Drug Disease Associations`
   [https://www.kaggle.com/datasets/ompatel8/drugdisease-associations](https://www.kaggle.com/datasets/ompatel8/drugdisease-associations)
2. Download the CSV that corresponds to the merged drug disease associations.
3. Save it into the repository root as:

```text
finaldataset.csv
```

### Step 3. Install Python dependencies

Install the libraries required by the notebooks:

```bash
pip install pandas numpy matplotlib seaborn scikit-learn xgboost
```

The standard library modules (`gc`, `warnings`, `datetime`, `collections`, `time`) are included with Python.

### Step 4. Run the improved XGBoost pipeline

There are two common options.

#### Option A: Run as a Python script

If you store the provided pipeline code in a Python file (for example using the same contents as in `final_submission.ipynb`) you can run:

```bash
python final_submission.py
```

This will:

* Load `finaldataset.csv`
* Train the improved XGBoost model
* Generate all PNG figures
* Save `improved_xgboost_model.json`
* Save `improved_model_report.txt`
* Generate `demo_testcases_report.txt`

#### Option B: Run from the notebook

1. Start Jupyter Notebook or JupyterLab.
2. Open `final_submission.ipynb`.
3. Ensure `FILEPATH` is set to `'finaldataset.csv'`.
4. Run all cells in order.

To regenerate the demo testcases report separately, open `testcases_final_submission.ipynb` and run its cells. This notebook calls `generate_demo_testcases_report` using the trained model and test split.

---

## 7. Branches and Other Models

* The **main** branch focuses on the improved **XGBoost** model, which demonstrated the best Top K performance on this dataset.
* Implementations for **LightGBM**, **CatBoost** and a **deep neural network** are available on the other branches of this repository.

To inspect the other models:

1. In GitHub, use the branch selector to switch from `main` to the desired branch.
2. Or in a local clone:

```bash
git fetch
git branch -a
git checkout <branch-name>
```

Replace `<branch-name` with the actual branch name corresponding to the model of interest. Each branch contains code specific to that model while using the same underlying dataset.

---

## 8. Summary of Key Results

On the balanced subset of the merged dataset (189 057 samples, 576 diseases, 16 features), the improved XGBoost model achieves:

* **Top 1 accuracy:** 22.69 percent
* **Top 3 accuracy:** 77.80 percent
* **Top 5 accuracy:** 95.46 percent
* **Top 10 accuracy:** 99.75 percent

The model:

* Uses balanced sampling and class weights to mitigate class imbalance.
* Applies stronger regularization (tree depth, learning rate, gamma, L1 and L2 penalties).
* Incorporates six domain motivated engineered features.
* Emphasizes Top K accuracy, which reflects how often the true disease appears in a short ranked list of candidate indications.

These results show that the model is effective at narrowing a very large set of possible diseases to a small set of promising candidates for repurposing studies.

Github Repo Link: https://github.com/meldridge12/Repurposing-Drugs

---

## 9. References

[1] Stanford Network Analysis Project (SNAP), "DCh Miner: Drug Combination Miner Dataset." Available online at the SNAP biodata collection.

[2] S. Guillemart, "DrugBank Dataset," Kaggle.

[3] Comparative Toxicogenomics Database (CTD), "CTDbase: Chemical Gene Disease Interactions."

[4] GeeksforGeeks, "XGBoost - Extreme Gradient Boosting Algorithm in Machine Learning."

[5] GeeksforGeeks, "LightGBM - Light Gradient Boosting Machine."

[6] CatBoost, "CatBoost: Open source Gradient Boosting Library."

[7] PyTorch, "Build the Neural Network," PyTorch Tutorials.

[8] O. Patel, "Drug Disease Associations," Kaggle dataset used for this repository.
